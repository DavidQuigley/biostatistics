---
title: 'Module 3.1: Data types'
author: "David Quigley"
output:
  pdf_document:
    toc: yes
  html_document:
    css: swiss.css
    toc: yes
  word_document:
    toc: yes
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set( prompt=TRUE ) 

knitr::knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(left.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(med.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(bottom.mar = function(before, options, envir) {
    if (before) par(mar = c(3, 2, 1, 1))  # smaller margin on top and right
})
```


```{r echo=FALSE}
height = c(7,8,7,9.5)
weight = c(4,3.2, 3.7, 5.4)
myTable=data.frame(height, weight)
rownames(myTable)=c('Flopsy','Mopsy','Cottontail','Peter')

my_observations = rnorm(1000, mean=50, sd=10)
my_bivariate = c( rnorm(1000, mean=50, sd=5), rnorm(1000, mean=65, sd=5) )
pap_no = c( 9,17,9,0,15,12,7,0,0,0,13,10,0,0,0,8,1,7,4,
  7,2,12,1,4,0,35,6,9,0,0,12,16,16,0,6,3,0,4,
  0,0,0,0,3,2,1,7,5,23,2,3,3,5,0,3,5,17,1,
  1,4,21,0,0,2,14,5,2,0,3,6,2,1)

MCV = c( 59.5,49.0,48.7,50.1,49.9,54.5,57.0,63.2,47.5,65.1,63.5,61.3,77.3,50.2,50.9,66.4,62.1,49.7,58.2,60.0,54.8,45.3,48.8,61.2,47.8,53.4,60.1,61.4,
57.9,61.2,62.1,64.6,61.3,45.8,65.9,47.6,59.4,63.5,52.2,51.8,75.9,51.3,60.6,55.7,69.3,50.5,57.7,54.6,67.7,60.5,54.4,58.6,73.6,60.0,53.2,49.6,
56.4,62.0,48.9,52.9,50.1,56.3,56.6,64.3,59.3,57.3,57.2,48.1,46.6,45.2,48.7,60.6,48.0,47.5,52.7,49.7,56.4,51.2,46.1,43.8,51.7,47.4,59.0,54.1,
47.9,43.6,47.6,53.7,45.2,48.7,49.7,46.6,51.2,46.1,50.6,54.2,47.4,52.7,51.7,50.6,49.5,55.1,51.9,59.6,46.3,51.0,48.3,50.2,56.5,56.3,46.5,45.8,
55.3,47.0,49.8,47.6,56.9,55.4,52.9,58.1,58.2,56.0,57.0,48.6,55.4,58.3,57.2,58.6,55.0,65.5,60.7,45.5,44.1,47.2,50.4,46.7,55.1,52.5,53.1,55.2,
52.3,50.5,48.9,45.2,53.3,48.4,55.0,55.4,49.2,43.6,52.2,51.6,49.0,51.0,60.4,45.7,55.0,50.5,46.8,46.4,46.5,54.4,46.1,48.4,56.1,55.2,56.8,58.1,
47.7,55.0,58.6,55.2,47.2,46.5,58.2,56.7,58.9,57.3,54.2,54.6,54.9,55.7,54.7,56.1,55.3,51.1,48.3,46.2,51.6,54.7,49.9,54.0,55.8,49.6,46.2,58.4,
52.4,44.7,47.8,59.2,57.3,49.6,45.9,44.3,57.0,44.4,47.8,49.4,50.7,56.0,47.6,52.8,46.0,47.6,51.4,55.4,45.5,46.2,47.1,51.3,52.4,49.4,48.0,46.2)

```

Introduction
========================================


**This module explains:**

* The definition of a random variable
* Data types
    + continuous
    + categorical
    + ordinal
* The implications of chosing a data type

Random variables and data types
================================================================================

Experiments observe the outcome of random processes
------------------------------------------------------------

The data collected by laboratory and field experiments can take many forms: counts: binary yes/no values indicating whether a person has had a heart attack, numbers indicating blood pressure readings, categories indicating which type of dementia patients have experienced, or ordered values indicating the number of alleles of a rare gene are present in a subject's DNA. Statisticians call these observed data *random variables* to indicate that their values were not pre-determined. 

The use of the word "random" does *not* mean that the observations are entirely unpredictable. It means that the value for a given observation is due, in part, to chance effects, and repetition of the experiment would not produce identical results. We use the term *random variable* even for data where all of the possible values for that observation can be enumerated. A coin flip is by convention either *heads* or *tails*, but the outcome of a series of flips is a random variable.  

The most frequently encountered data types are *continuous*, *ordinal*, and *categorical* data. 

Continuous variables
----------------------------

Continuous data are numbers that can take any real value; that is, they could take any value on a number line. Height and weight are continuous variables. Continuous variables can be constrained in certain ways; age in days is continuous and positive, and might be constrained to  be rounded to the nearest whole number. 

Treating observations as continuous variables allows measurement of scale and the frequency. We can make precise claims about how much larger or smaller two continuous variables are compared to each other. In many cases, even if another representation for the data is chosen, or if the data are transformed in some way, it is important to have available the original continuous raw data. Analysis of continuous variables can be strongly affected by individual extreme values.

Ordinal variables
----------------------------

Variables that are not numbers, but which can be sorted into an invariant order, are ordinal. Ordinal variables do not need to have a specific numerical range. "weight group: Low, Medium, High" and "tumor grade: Grade I, Grade IIA, Grade IIB, Grade III, Grade IV" are ordinal variables. Some specialized statistics such as the Cochranâ€“Armitage test for trend can be applied to ordinal variables.

Binning values into ordinal categories is an important strategy when there is general agreement about the implications of the bins, but the exact set of values that assign an observation to that bin are either not strictly numeric, or are subject to a bit of wiggle room. Pathologists will often bin their observations of cell morphology or slide staining intensity into categories such as ("absent", "mild", "severe") for this reason. 

Categorical variables
----------------------------

Categorical data are observations that fall into cleanly definable groups that lack an ordering. The eye color of a patient can be coded as a categorical variable: (*Brown*, *Blue*, *Green*, *Grey*).  Boolean (TRUE/FALSE) data are a special case of categorical data with exactly two categories.

Statisticians often refer to categorical variables as *factors*. Although categorical variables are sometimes coded using numbers (e.g. red=1, blue=2, orange=3...) this can lead to confusion if you apply a statistical test that interprets the numbers as having an inherent meaning. 

Counts are derived from categorical data
------------------------------------------

Counts are integers of value zero or higher. Counts refer to the number of times we observed the outcome of some process that generates discrete outcomes in a categorical or ordinal group. Counts are of particular interest because they are the appropriate data for Fisher's Exact Test and the chi-squared test.

The R function *table()* is very useful for converting a list of observations into counts:

**Example 1: counting the appearances of a categorical variable**
```{r}
categories = c('a','a','a','a','a','b','b','b','c','d','d','d','d','d','d','d')
table(categories)
```


Choice of data type affects the analysis
================================================================================


The same BMI data, three way
------------------------------------

The main reason to stress data types is that **the form of a variable involves a choice by the investigator**. Although it may seem that some values have intrinsic data types, there usually exists the possibility of further transforming data into some other format. This choice has consequences. As an example, consider Body Mass Index (BMI), a proxy measure of obesity that incorporates height and weight. BMI is a continuous variable. You could make different choices about how to represent BMI in your experiment, among them:

**Continuous variable**  
Report the raw value for the subject's BMI

**Ordinal variable**  
Divide subjects into categories, such as Low, Medium, and High BMI. 

**Categorical variable**: divide patients into Obese and Not Obese categories. 

To place subjects into an ordinal group or category requires making a decision about the cut-off values for each category. Seemingly small differences in the choice of cut-off can have large consequences for the interpretation of the data you collect.

The choice of how to fit continuous data into categories is very important. In some analysis, where there is no common convention, you will be able to decide on your own categories. These decisions have to be well-motivated, and ideally should take place before you see the data that will be generated. If the categories are fit to the data *post hoc*, they can be a source of bias.

In some cases, standardized value for the ranges of data that should fit into a particular category will be established by informal common scientific conventions or by formal standards bodies. Knowing whether these standard definitions apply to your analysis is extremely important for clear communication and for clinical relevance if your study describes medical information. 

A simple example of flexible group membership
---------------------------------------

In this example, whether a given pair of subjects is grouped together will depend on the bounds that are chosen. 

![](images/module_03_1_BMI.png)

**Table 1: BMI represented three ways**

These data are shown grouped into (low, high), or by ranges (0-10, 10-20, or 20+). The samples with measurements of 18 and 25 are grouped as "high" in this example, while they are in different categories when grouped by range. 

Grouping in this manner also tends to reduce the effect of extreme values. Plotting the raw values would show there is an extreme value of 147, which is unlikely to be a correct measurement. Simply binning that value into "high" or "20+" will disguise the extreme value. We will later see in [Module 8.1: Robust statistics and Outliers](module_08.1.html) how the presence of extreme values can dramatically effect the results of some analysis that uses data in the form of continuous variables.

The perils of redefining categories
---------------------------------------

As a hypothetical example demonstrating the consequences of these choices in a more realistic way, let us say a group is investigating the use of a standard blood test as a prognostic tool. A value below five units is considered a physiologically relevant threshold, so the study asks whether testing that indicates the blood value is less than five units is predictive of disease outcome. Outcome in this example is dichotomized into good and poor categories.

```{r echo=FALSE}

#x=c( rnorm(10, 3), rnorm(50, 5.5), rnorm(10, 8) )
x=c(3.76,4.17,3.66,4.48,2.63,4.34,0.10,2.99,3.03,0.92,7.13,5.70,5.52,6.43,
    5.66,4.64,6.00,4.09,4.78,4.72,6.02,6.63,5.56,4.15,3.97,8.08,5.56,5.91,4.75,
    5.40,5.89,5.49,5.01,4.61,6.57,4.74,6.49,5.69,3.16,3.80,5.94,5.39,5.57,
    4.57,4.42,6.52,6.71,4.57,4.76,6.45,5.40,3.95,6.11,7.38,5.65,5.21,6.41,
    4.24,4.28,7.81,6.44,8.03,9.58,7.64,8.45,8.66,10.99,8.50,6.81,6.16)

lbl = rep("poor", length(x))
lbl[1:8] = "good"
lbl[55:62] = "good"
lbl[x==sort(x)[69]] = "good"

df = data.frame(x, lbl, stringsAsFactors=FALSE)
df = df[order(df$x),]
color=rep("black", dim(df)[1])
color[df$lbl=="poor"] = "cornflowerblue"
par(mar=c(3,3,1,1))
barplot(df$x, col=color, las=1, xaxs="i", yaxs="i")
box()
legend( 1, 9, c("Good outcome","Poor outcome"), 
        col=c("black", "cornflowerblue"), pch=19)
abline(5,0)
```

**Figure 1: data from the blood test**

In their first analysis, the investigators bin the measurements into samples that are greater than 5 or not. This produces a two-by-two table with low blood value on one axis and disease outcome on the other. They find that 28 patients had low blood value; of the 28, 10 had good outcomes while 18 had poor outcomes. The statistical method they use (Fisher's exact test) is described in [Module 7.1: Counts and categories: The Binomial, Chi-squared and Fisher's Exact tests](module_07.1.html). Using the hypothesis testing methods we will explore in [Module 4.2: Making decisions with P values](module_04.2.html), the test produces a result that is not incompatible with a chance finding at the threshold for significance they had previously chosen, and at this point the investigators would be forced to report that they failed to establish an association between low blood value and disease outcome.

```{r}
fisher.test( matrix( c(
              sum( x<5 & lbl=="good" ), 
              sum( x<5 & lbl=="poor" ), 
              sum( x>=5 & lbl=="good" ), 
              sum( x>=5 & lbl=="poor" ) ), nrow=2, ncol=2)
             )
```

One investigator notices that there is a cluster of good outcome patients at the lower end of the sorted list of values, and asks whether turning the question around and testing for an  association between the raw blood value and outcome would identify a meaningful association. However, testing using a *t* test (described in [Module 5.4: The t test: comparing the mean between groups](module_05.4.html) )is also not statistically significant. 

```{r}
t.test(x~lbl)
```

Not willing to give up, the investigators decide to stratify their data in an *ad hoc* manner  and compare the bottom 25% of samples to the rest of the data.

```{r}
fisher.test( matrix( c(
              sum( x<quantile(x)[2] & lbl=="good" ), 
              sum( x<quantile(x)[2] & lbl=="poor" ), 
              sum( x>=quantile(x)[2] & lbl=="good" ), 
              sum( x>=quantile(x)[2] & lbl=="poor" ) ), 
              nrow=2, ncol=2)
             )
```

The result of this test is declared statistically significant.

There are several unflattering terms for this kind of analysis, including "data dredging" or "P-hacking". It should be pretty clear that the analysts kept moving the goalposts until they came up with a result that matched their desired outcome. I include this example as an example of what **not** to do, and also as a cautionary tale. If a study uses arbitrary bounds for categorizing data, or uses different bounds in different situations, one should ask:

1. why were those bounds chosen?
2. how would the conclusions change with a different choice of bounds?

Summary
============

* Data types
    + continuous: real-valued numbers
    + ordinal: ordered, but not real-valued
    + categorical: unordered
* Choice of data type affects
    + which statistical test can be applied
    + interpretation
* Look closely at how you and others group data

R code examples
=======================

Convert strings to factors
--------------------------------------------------------------------------------

We will collect six measurements for eye color, store them to a vector called eye_color, and then convert the the vector to a factor

```{r}
eye_color = c("brown", "blue", "blue", "green","blue","grey")
eye_color
f_eye_color = factor(eye_color)
f_eye_color
```

Note that after using the *factor()* function, printing out the variable *f_eye_color* returns both the strings and a list of the **Levels**, or unique names, that make up the factor.


The following example illustrates what can happen if you code categorical values as numbers and then accidentally forget that they're categories:

**Example 1: the mean of a vector of colors**
```{r}
red = 1
blue = 2
orange = 3
color_list = c(red, red, orange, blue, blue, blue)
mean(color_list)
```

The idea of a mean of a vector of categories doesn't make sense, since the number assignments have no inherent meaning.

R has a function *factor()* which converts a vector of categorical variables, usually words, into factors. The variable then retains its appearance as words, but R will know that these words should be treated as categories. Taking the mean of a vector of factors will generate a Warning message. This isn't a syntax error, but R knows you're probably doing something you don't really mean to do, and the result is *NA*.

**Example 2: the mean of a vector of factors**
```{r}
color_list = c("red", "red", "orange", "blue", "blue", "blue")
color_list = factor( color_list )
color_list
mean(color_list)
```

