---
title: "Module 3.3: Distributions, normal and otherwise"
author: "David Quigley"
date: "September 25, 2015"
output: 
    html_document:
        toc: true
        css: swiss.css
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set( prompt=TRUE ) 

knitr::knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(left.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(med.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(bottom.mar = function(before, options, envir) {
    if (before) par(mar = c(3, 2, 1, 1))  # smaller margin on top and right
})
```


```{r echo=FALSE}
height = c(7,8,7,9.5)
weight = c(4,3.2, 3.7, 5.4)
myTable=data.frame(height, weight)
rownames(myTable)=c('Flopsy','Mopsy','Cottontail','Peter')

my_observations = rnorm(1000, mean=50, sd=10)
my_bivariate = c( rnorm(1000, mean=50, sd=5), rnorm(1000, mean=65, sd=5) )
pap_no = c( 9,17,9,0,15,12,7,0,0,0,13,10,0,0,0,8,1,7,4,
  7,2,12,1,4,0,35,6,9,0,0,12,16,16,0,6,3,0,4,
  0,0,0,0,3,2,1,7,5,23,2,3,3,5,0,3,5,17,1,
  1,4,21,0,0,2,14,5,2,0,3,6,2,1)

MCV = c( 59.5,49.0,48.7,50.1,49.9,54.5,57.0,63.2,47.5,65.1,63.5,61.3,77.3,50.2,50.9,66.4,62.1,49.7,58.2,60.0,54.8,45.3,48.8,61.2,47.8,53.4,60.1,61.4,
57.9,61.2,62.1,64.6,61.3,45.8,65.9,47.6,59.4,63.5,52.2,51.8,75.9,51.3,60.6,55.7,69.3,50.5,57.7,54.6,67.7,60.5,54.4,58.6,73.6,60.0,53.2,49.6,
56.4,62.0,48.9,52.9,50.1,56.3,56.6,64.3,59.3,57.3,57.2,48.1,46.6,45.2,48.7,60.6,48.0,47.5,52.7,49.7,56.4,51.2,46.1,43.8,51.7,47.4,59.0,54.1,
47.9,43.6,47.6,53.7,45.2,48.7,49.7,46.6,51.2,46.1,50.6,54.2,47.4,52.7,51.7,50.6,49.5,55.1,51.9,59.6,46.3,51.0,48.3,50.2,56.5,56.3,46.5,45.8,
55.3,47.0,49.8,47.6,56.9,55.4,52.9,58.1,58.2,56.0,57.0,48.6,55.4,58.3,57.2,58.6,55.0,65.5,60.7,45.5,44.1,47.2,50.4,46.7,55.1,52.5,53.1,55.2,
52.3,50.5,48.9,45.2,53.3,48.4,55.0,55.4,49.2,43.6,52.2,51.6,49.0,51.0,60.4,45.7,55.0,50.5,46.8,46.4,46.5,54.4,46.1,48.4,56.1,55.2,56.8,58.1,
47.7,55.0,58.6,55.2,47.2,46.5,58.2,56.7,58.9,57.3,54.2,54.6,54.9,55.7,54.7,56.1,55.3,51.1,48.3,46.2,51.6,54.7,49.9,54.0,55.8,49.6,46.2,58.4,
52.4,44.7,47.8,59.2,57.3,49.6,45.9,44.3,57.0,44.4,47.8,49.4,50.7,56.0,47.6,52.8,46.0,47.6,51.4,55.4,45.5,46.2,47.1,51.3,52.4,49.4,48.0,46.2)

```



**This module defines what is meant by a statistical variable. It introduces the fundamental tools used to describe the behavior of a variable, including the mean, standard deviation, histograms, and normal distribution.**




Summarizing data: variance and standard deviation
======================================================================

The mean provides a single point estmate the middle value of the data. The variance summarizes the amount of spread, or dispersion, around the mean of the observations. To calculate the variance we sum the average difference between each individual measurement and the mean, and then divide by the number of measurements. If a distribution is more spread out, then these deviations will be larger on average and the variance will in turn be higher. Since observations could be larger than or smaller than the mean, we compute the square the differences.

$\large{ \textit{variance} = \sigma^2 = \frac{ \sum\limits_{i=1}^N{ (v_n - \mu)^2 }} {N} }$

Note that because we sum over the square of the differences, as opposed to simply using a positive distance such as the absolute value, a point's influence over the variance increases dramatically as the distance from the mean increases. As a result, even if most observations are relatively close to the mean, it takes only one value that is quite distant from the mean to make the variance very large.

The variance is mathematically important, but since we square the individual deviations from the mean in order to calculate the variance, the variance itself is not in the same units as the underlying measurements. That is, if your measure is in inches, the variance will be in inches-squared. This is often inconvenient, so we usually take the square root of the variance to match up the units measuring dispersion with the units measuring mean. The square root of the variance is called the standard deviation.

$\large{ \textit{standard deviation} = \sigma = \sqrt{ \textit{variance} } }$

The mean and standard deviation together do a good job of describing the central tendency and spread of many data sets that are generated by natural processes. They are particularly useful when the data tend to cluster near the mean and fall off in frequency in either direction in a bell-shaped distribution called the *normal distribution*. 

The normal distribution
======================================================================

For centuries observers of the natural world have known that natural phenomena that act as random variables, such as the height of pine trees in a forest, tend to follow a bell-shaped distribution. Most subjects have values near the center of the distribution. More extreme values are progressively rarer, with frequencies that drop off to near-zero values quickly. This distribution was formalized as the so-called Normal distribution

The normal distribution plays a fundamental role in biostatistics, and we will spend some time exploring its uses.

Features of the normal distribution
------------------------------------------------

A Normal distribution has several features:

* It is always positive; away from the middle it gets very close to zero, but never crosses zero.
* The area under the curve is always equal to one
* The curve is symmetric around the midpoint

The X axis for a Normal curve is measured in standard units. 

```{r echo=FALSE, fig.width=4, fig.height=3}
par(mar=c(4,4,2,1))
x = seq(-4,4,length=1000)
y = dnorm(x,mean=0, sd=1)
plot(x,y, type="l", lwd=1, ylab="Density", xlab="Standard units", main="standard normal curve")
```

The mean of this distribution is zero, and the standard deviation is one.

The standard normal distribution 
------------------------------------------------

* describing a curve using the mean and variance
* Obtaining z-scores from the mean and standard deviation

reasoning about the rarity of events using the z score
------------------------------------------------



Error bars

When do I use the SD? When do I use the SEM?

