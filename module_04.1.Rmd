---
title: "Module 4.1: The normal distribution"
author: "David Quigley"
date: "September 25, 2015"
output: 
    html_document:
        toc: true
        css: swiss.css
---


*In this module, I will introduce the concept of statistical distributions and focus on the standard normal distribution. I will also introduce other distributions that are frequently useful: the t distribution, the exponential distribution, the sigmoidal distribution*


What is a statistical distribution?
--------------------------------------------------------------------------------

A statistical distribution is a mathematical function. Mathematical functions precisely define a one-to-one relationship between a set of input variables and an output variable. $y = x^2$ is an example of a function. It is often useful to plot the values of a function, as its shape can tell us something about how the function behaves for different values of X:

```{r echo=FALSE, fig.height=3, fig.width=3}
library(grDevices)
vals = seq(from=-3,to=3, by=0.01)
par(mar=c(4,5,2,1))
plot( vals, vals^2, xlab="X", ylab=expression(X^2), xaxs="i",yaxs="i",las=1, type="l", lwd=3, main= expression( plain("Y=")*X^2) )
```

This function is well-defined: for all of the allowed values of X, there is exactly one value of Y that can be obtained by squaring the value of X. Distributions are well-defined functions that have an additional constraint: the area between the distribution's Y value and the zero line of the Y axis must sum to exactly one. The function $y = x^2$ is not a distribution, because the area under $y = x^2$ is infinite.

The simplest distribution has a single constant value for Y at every allowed value of X:

```{r echo=FALSE, fig.height=3, fig.width=7}
layout(matrix(1:2,1,2))
par(mar=c(4,5,2,1))
plot( 1,1, xlab="X", ylab="density", xaxs="i",yaxs="i",las=1, col="white",ylim=c(0,0.45), xlim=c(0,10), main="Unform distribution" )
lines(c(0,10), c(0.1, 0.1), lwd=3)

plot( 1,1, xlab="X", ylab="density", xaxs="i",yaxs="i",las=1, col="white",ylim=c(0,0.45), xlim=c(0,10), main="Unform distribution" )
vals = seq(from=0, to=10, by=0.01)
for(i in 1:length(vals)){
    x = vals[i]
    lines(c(x,x), c(0,0.1), col="cornflowerblue")
}
lines(c(0,10), c(0.1, 0.1), lwd=3)
```

The plot on the left is a distribution; although we sometimes refer to a distribution as a "curve", there is no rule that says a distribution cannot be a straight line. If you were to sum up the total area under the line, plotted in blue on the right side, you would find it equals exactly one. This distribution has a uniform value for Y at every X; it is therefore called the **uniform distribution**. Note that if we extended the plot to the right past 10 or to the left past 0, the area under the curve would exceed one and the curve could no longer be a distribution. Some distributions therefore will have **bounds**, values that they cannot exceed. 


What are distributions useful for?
--------------------------------------------------------------------------------

When we collect data, the values of a random variable will be different; by definition, they will vary. Although some processes appear to generate random noise with no pattern in the values, most data generated by sampling properties of living things follow a common frequency distribution:  most values are near the mean value, and more extreme values appear much less frequently:

```{r echo=FALSE, fig.height=3, fig.width=4}
par(mar=c(3,3,1,1))
vals=c(29.3,31.5,29.9,28.9,30,29.4,29.6,30.5,29.5,30,30.7,30.6,28.6,30.8,29.1,30.9,29.4,
28.8,29.7,29.1,30.7,31,29.3,28.5,28,30.8,28.1,31.1,31.3,28.6,29.5,29.6,30.6,29.4,
30.6,29.3,30.1,28.6,29.7,31.2,30.1,30.2,30.2,29.1,30,30,29.7,31.3,28.6,30.5,29.6,
29.1,29.9,29.5,29.8,31.4,29.1,31.8,31,29.4,31.7,31.4,30.6,29.4,30.6,30.7,29,29.1,
30.1,30.3,29.9,31.4,28.6,30.3,28.9,28.7,29.6,29.2,31.1,32.5,29.9,31.3,30.9,28.6,
30.3,30.8,30.1,29.8,29.5,29.4,30.8,30.4,30.3,31.6,29.9,29.3,31.1,30,29.8,29.2,30.6,
31.1,30.9,29.6,29.2,30.1,31.9,30.5,29.6,30.6,29.9,28.9,30.7,30.4,30.4,28.7,28.2,
29.4,29,29.8,30.5,31.3,29.1,29.4,30.9,29.6,27.3,30.8,29.4,30.1,30.8,28.8,30.7,
31.1,30.9,29.7,29.4,28.6,30.6,28.7,31,29.5,29.7,30,30.4,28.9,30.4,30,30.5,30.7,
27.1,29.5,30.2,32.3,28.6,31.5,32.7,29.8,27.1,30.2,29.6,28.8,29.9,29.2,30.7,31.9,
30,29.9,30.4,29.8,31.3,28.9,29.6,31.1,28.5,29.1,30.1,30.4,31.3,29.4,29.8,31.6,
30.1,30.1,30.1,30.7,31.9,28.7,31.2,29.5,30,29,30,28.9,30,28.8,31.1,29,29.3,29.9)
hist(vals, breaks=30, col="lightgrey", las=1, main="Histogram of typical data", ylim=c(0,22) )
lines( c( mean(vals), mean(vals) ), c(0, 22), col="cornflowerblue", lwd=3)
text( mean(vals)+0.5, 21, "Mean")
```

This frequency plot produce a bell-shaped curve. Variations on this curve appear over and over again as we sample the real world: the height of 10-year-old children in Maryland, the weight of rabbits raised in captivity, etc. That's not to say that all data are normally distributed, but the distribution appears frequently enough that it serves as a yardstick: either data are normally distributed, or they are something else.

As we obtain larger and larger samples of biological data, the frequency plot of the sample value distribution will tend towards a particular distribution.

```{r echo=FALSE, fig.height=4, fig.width=9}
layout(matrix(1:3,1,3))
vals = seq(from=-5,to=5, by=0.01)
par(mar=c(6,4,3,3))
hist(rnorm(1000), breaks=100, probability=TRUE, las=1, ylim=c(0,0.6), border="gray", col="gray", main="histogram vs. distribution", xlab="N=100")
points( vals, dnorm(vals), type="l", lwd=2, col="cornflowerblue" )
hist(rnorm(10000), breaks=100, probability=TRUE, las=1, ylim=c(0,0.6), border="gray", col="gray", main="histogram vs. distribution", xlab="N=1,000")
points( vals, dnorm(vals), type="l", lwd=2, col="cornflowerblue" )
hist(rnorm(100000), breaks=100, probability=TRUE, las=1, ylim=c(0,0.6), border="gray", col="gray", main="histogram vs. distribution", xlab="N=10,000")
points( vals, dnorm(vals), type="l", lwd=2, col="cornflowerblue" )
```


Although real data will never be identical to the distribution, the frequency distribution of real data will often be close enough to a distribution that we can use the distributon as a stand-in for the observed data. This is useful for many statistical tasks. For example, we can estimate the frequency of all possible values for the variable, as though we had an infinitely large data set. A useful consequence of using a defined function as a frequency estimate is we have a way to ask the question, "how frequently would we expect to see values of a certain magnitude, if they were generated by this distribution?" This is the fundmental question we need to answer for problems of comparison and hypothesis testing, which will be explored in module 5.

The fact that distributions are used to reason about the frequency of events is the explanation for why their area must sum to one: the total area under the distribution is the total possible range of frequency values, which has a minimum of zero (the event never happens) and a maximum of one (or 100%), meaning the event always occurs.


The standard normal distribution has a special and unique role as a kind of ideal histogram. The word 'standard' is derived from the fact that the distribution has been scaled on the horizontal axis so that one unit on the horizontal axis corresponds to the magnitude of one standard deviation. The standardization is important because it allows us to compare two or more samples with values on different scales to the standard normal curve; if values from sample one are exactly twice the size of values from sample two, they will have the same standardized distribution. 

Not all distributions are symmetrical around zero, but this one is; that means that its mean is zero. You can see that the Y value drops quickly to the X axis; although it never touches the X axis, it gets asymptotically close and is very, very close already when X equals -4 or 4.  

```{r echo=FALSE}
vals = seq(from=-5,to=5, by=0.01)
par(mar=c(4,5,2,1))
plot( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
for(i in 1:length(vals)){
    x = vals[i]
    y = dnorm(x)
    lines(c(x,x), c(0,y), col="cornflowerblue")
}
points( vals, dnorm(vals), type="l", lwd=3 )
```

The formula that defines this distribution, which is not something you need to memorize, is rather complicated:

$\large{y = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}}$

Where *e* is the special mathematical constant that starts 2.71828, and $\pi$ is the special mathematical constant that starts out 3.141593. Since this formula is difficult to work with by hand, in the past it was common to use look-up tables to obtain the height of the standard normal curve at a given value of X. Now it is easier to use statistical packages such as R to calculate the area under this curve between two points. However, there are a few key values that are important to know:

* Between -1 and 1: lies about 0.68, or 68%.
* Between -2 and 2: lies about 0.95, or 95%.
* Between -3 and 3: lies about 0.997, or 99.7%.

```{r echo=FALSE, fig.height=4, fig.width=9}
layout(matrix(1:3,1,3))
vals = seq(from=-5,to=5, by=0.01)
par(mar=c(4,5,2,1))
plot( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
for( i in seq(from=-1, to=1, by=0.01)){
    lines( c(i,i), c(0, dnorm(i)), col="cornflowerblue", lwd=2)
}
axis(1, -5:5)
points( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
text(0,0.2,"68%", cex=2)

plot( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
for( i in seq(from=-2, to=2, by=0.01)){
    lines( c(i,i), c(0, dnorm(i)), col="cornflowerblue", lwd=2)
}
axis(1, -5:5)

points( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
text(0,0.2,"95%", cex=2)
plot( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )
axis(1, -5:5)
for( i in seq(from=-3, to=3, by=0.01)){
    lines( c(i,i), c(0, dnorm(i)), col="cornflowerblue", lwd=2)
}
text(0,0.2,"99.8%", cex=1.6)
points( vals, dnorm(vals), xlab="standard units", ylab="density", xaxs="i",yaxs="i",las=1, 
      type="l", lwd=3, ylim=c(0,0.45), main="Standard normal distribution" )

```


These bounds have important implications for how we interpret the likelihood of seeing data; for samples that are normally distributed, or close a normal distribution, 95% of the data will fall within two standard deviations of the mean value.



Student's t distribution
================================================================================

The fact that as the number of observations increase, their values will often tend towards a normal frequency distribution allows statisticians to make important inferences about statistical properties. However, in practice, scientists often are constrained to use small sample sizes. Depending on experimental costs, expenses, or the availability of subject populations, it is not uncommon to operate on small sample sizes. The *t* distribution is very useful in these cases. The *t* distribution is sometimes named Student's *t* distribution after the pseudonym of the statistician William Sealy Gosset, who developed it while working at the Guiness Brewery.

The t distribution describes the frequency distribution of small numbers of samples chosen from a normal distribution. Like the normal distribution, the function that defines its probability density is complex and understanding it is not required to make use of the *t* distribution.

Recall that for *n* samples, the sample mean is defined:

$\bar{x} = \frac{x_1 + ... + x_n}{n}$ 

and the sample variance is defined:

$s^2 = \frac{ \sum_{i=1}^n(x_i-\bar{x})^2 }{n-1}$. 

The *t* value for an individual sample of size *n* from of a population with mean $\mu$ is given by:

$\large{t = \frac{\bar{x}-\mu}{ \frac{s}{\sqrt{n} } }}$

So *t* will increase as 

1) *n* increases
2) *s* (the standard deviation, $\sqrt(variance)$) decreases
3) the difference between $\bar{x}$ and $\mu$ decreases

Note that this equation defines the *t* statistic for a particular observation; the *t* distribution describes the frequency with which one would observe all possible *t* statistics for a given number of degrees of freedom. The distribution of the *t* statistic is symmetric around zero. It is shaped like a standard normal distribution, but its tails do not get close to zero quite as quickly as a standard normal curve; in statistical jargon, it has "fatter tails". The shape of the *t* distribution is influenced by on the number of degrees of freedom. The degrees of freedom for a *t* statistic is equal to the number of samples minus one. As the number of degrees of freedom increases, the *t* distribution becomes more simlar to a normal distribution:

```{r echo=FALSE, fig.height=4, fig.width=8}
vals = seq(from=-7,to=7, by=0.01)
layout(matrix(1:2,1,2))
par(mar=c(4,4,1,1))
plot(dt( vals, df=1 ), type="l", yaxs="i", xaxs="i", lwd=3, axes=FALSE, 
     xlab="t statistic", ylab="density", main="t and standard normal distribution", ylim=c(0,.4) )
points( dnorm( vals ), type="l", lwd=3, col="gray" )
legend( 900,0.35, c("t DF=1", "normal"), col=c("black", "gray"), pch=19)
axis(2, seq(from=0, to=0.4, by=0.1), las=1)
axis(1, at=( length(vals) / 14 * 0:14) , labels=seq(from=-7, to=7, by=1), las=1)

plot(dt( vals, df=1 ), type="l", yaxs="i", xaxs="i", lwd=3, axes=FALSE, 
     xlab="t statistic", ylab="density", main="t and standard normal distribution", ylim=c(0,.4) )
axis(2, seq(from=0, to=0.4, by=0.1), las=1)
axis(1, at=( length(vals) / 14 * 0:14) , labels=seq(from=-7, to=7, by=1), las=1)
points( dt( vals, df=3 ), type="l", lwd=3, col="cornflowerblue" )
points( dt( vals, df=6 ), type="l", lwd=3, col="gold" )
points( dt( vals, df=20 ), type="l", lwd=3, col="darkgreen" )
points( dnorm( vals ), type="l", lwd=3, col="gray" )
legend( 900,0.35, c("t DF=1","t DF=3","t DF=6","t DF=20", "normal"), col=c("black", "cornflowerblue", "gold", "darkgreen", "gray"), pch=19)
```

The formula describing the *t* distribution is rather complicated. In the past to derive a specific value for the distribution, given a value for *t* and the number of degrees of freedom, one would have used a table of pre-computed values. Nowadays we can use a statistical package such as R to do this. 

> R code to derive the *t* distribution value for a given degrees of freedom: dt(t_value, df=degrees)
