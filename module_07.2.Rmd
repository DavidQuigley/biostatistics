---
title: 'Module 7.2: The Poisson Distribution'
author: "David Quigley"
output:
  html_document:
    css: swiss.css
    toc: yes
  word_document:
    toc: yes
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set( prompt=TRUE ) 

knitr::knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(left.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(med.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(bottom.mar = function(before, options, envir) {
    if (before) par(mar = c(3, 2, 1, 1))  # smaller margin on top and right
})
```

Introduction
========================================

**This module explains:**

* How the Poisson distribution can be used to model discrete, rare events

Counts of rare events: the Poisson distribution
--------------------------------------------------------------------------------

The Poisson distribution (from SimÃ©on Poisson, pronounced "Pwah-sohn"), is a discrete probability distribution. It is useful for describing the probability of seeing an event when several constraints are met:

* The number of events can be counted with whole numbers
* You know the mean event frequency (perhaps through observation)
* Events are independent of each other
* You can count the number of times the event occurred, but not the number of times an event did not occur.

The last point is stated very clearly in material produced by the Warring States Project:  

>This last point sums up the contrast with the Binomial situation, where the probability of each of two mutually exclusive events (p and q) is known. The Poisson Distribution, so to speak, is the Binomial Distribution Without Q. In those circumstances, and they are surprisingly common, the Poisson Distribution gives the expected frequency profile for events.

SOURCE: http://www.umass.edu/wsp/resources/poisson/index.html

The following equation calclates the exact probability of observing *x* events in a time interval when the event frequency is Poisson distributed:

$\large{ P(X) = \frac{e^{-\mu}\mu^x }{x!} }$

Where *e* is the mathematical constant *e* (2.71828...), $\mu$ is the mean number of events per time interval, and *x!* means "x factorial". The factorial operation means to multiply a value by all decreasing integers down to 1, so *4! = 4 x 3 x 2 x 1 = 24*. To come up with a value for $\mu$, one must either specify a value *a priori*, or observe a real system long enough that you are satisfied with your estimate. 

```{r echo=FALSE, fig.height=6, fig.width=7}
layout(matrix(1:3,3,1))
vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,1 ), xlab="trials", ylab="density", 
          main="Poisson distribution: mean=1", axes=FALSE, ylim=c(0,0.4) )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)

vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,2 ), xlab="trials", ylab="density", 
          main="Poisson distribution: mean=2", axes=FALSE, ylim=c(0,0.4) )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)

vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,3 ), xlab="trials", ylab="density", 
          main="Poisson distribution, mean=3", axes=FALSE, 
          ylim=c(0,0.4) )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)
```

**Figure 1: three Poisson distributions with varying means**

The Poisson approximation to the Binomial Distribution
--------------------------------------------------------------------------------

The Poisson distribution can be used to approximate the Binomial distribution, but this approximation is only accurate for rare events, e.g. those where the probability in any unit time window is less than 10%. Now that we can evaluate either of these distributions using packages such as R, the savings in computational complexity at the cost of loss of accuracy is less relevant than it once was.


Examples of applying the Poisson distribution
--------------------------------------------------------------------------------

**EXAMPLE ONE**:

A graduate student observes that most days, her principle investigator drinks two cups of espresso. What is the probability that the supervisor will drink three cups of expresso?

*Why use the Poisson distribution?* The student observes a discrete, infrequent event. She can tabulate the number of days the P.I. drank two cups of coffee, but cannot enumerate the number of possible outcomes that could have happened.

*Answer:* Here $\mu$ = 2, and we are asked to calculate P(3).

Since $\large{ P(X) = \frac{e^{-\mu}\mu^x }{x!} }$, $\large{ P(3) = \frac{e^{-2}\times2^3 }{3!} } = 0.180447$, or 18%.

> To raise *e* to a value in R, use the exp() function.

**EXAMPLE TWO**:

Mice of the strain RX47 usually produce five healthy pups in a litter. You have recently changed their chow to pellets produced by a different supplier, and the next litter from your RX47 mice has only three pups. Should you be worried? What are the chances that this might happen by chance?

*Answer:* Here $\mu$ = 5, and we are asked to calculate P(3).

$\large{ P(3) = \frac{e^{-5}\times5^3 }{3!} } = 0.2807$, or 28%. 

This suggests the evidence the change in chow was associated with lower litter sizes is not very strong.

**EXAMPLE THREE**:

Robert the Post Doc typically stays at the lab after 8:00 p.m. five times as week. His partner at home eats dinner at 6:30 p.m. What are the chances that Robert will miss dinner today?

The average number of days per week Robert is at work past 8:00 p.m. is $\frac{5}{7} = 0.71$. The probability that Robert will have a late night is $\frac{e^{-0.71}\times0.71^1}{1!}$ = 0.349 = 35%.


In this case, we can also calculate the probability of a late night using the Binomial distribution:

$P_{late} = 0.71$, $P_{not late} = 0.29$, so 

$\large{ {n \choose x} p^x(1-p)^{(n-x)} }$

Summary
=========

* The Poisson distribution is useful for modeling the frequency distribution of rare events

R code examples
=======================

>Obtain the probability of a positive result in 1 to 15 trials for a Poisson distribution with mean *mu*

The *dpois()* function returns the density of the poisson distribution at a given number of trials for a given mean.

```{r rank, comment=""}
mu=1
n_trials = seq(from=0, to=15, by=1)
probabilities = dpois(n_trials, mu )
data.frame( trials = n_trials, probability=signif( probabilities, 3 ) )
```




