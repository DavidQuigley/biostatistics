---
title: "Module 7.2: The Poisson Distribution"
author: "David Quigley"
date: "October 28, 2015"
output: 
    html_document:
        toc: true
        css: swiss.css
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(comment = NA)
knitr::opts_chunk$set( prompt=TRUE ) 

knitr::knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(left.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(med.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, 1, 1))  # smaller margin on top and right
})
knitr::knit_hooks$set(bottom.mar = function(before, options, envir) {
    if (before) par(mar = c(3, 2, 1, 1))  # smaller margin on top and right
})
```

Introduction
========================================

**This module explains:**

* How the Poisson distribution can be used to model discrete, rare events

Counts of rare events: the Poisson distribution
--------------------------------------------------------------------------------

The Poisson distribution (from SimÃ©on Poisson, pronounced "Pwah-sohn"), is a discrete probability distribution. It is useful for describing the probability of seeing an event when several constraints are met:

* The number of events can be counted with whole numbers
* You know the mean event frequency (perhaps through observation)
* Events are independent of each other
* You can count the number of times the event occurred, but not the number of times an event did not occur.

The last point is stated very clearly in material produced by the Warring States Project:  

>This last point sums up the contrast with the Binomial situation, where the probability of each of two mutually exclusive events (p and q) is known. The Poisson Distribution, so to speak, is the Binomial Distribution Without Q. In those circumstances, and they are surprisingly common, the Poisson Distribution gives the expected frequency profile for events.

*SOURCE: http://www.umass.edu/wsp/resources/poisson/index.html*

The following equation calclates the exact probability of observing *x* events in a time interval when the event frequency is Poisson distributed:

$\large{ P(X) = \frac{e^{-\mu}\mu^x }{x!} }$

Where *e* is the mathematical constant *e* (2.81929...), $\mu$ is the mean number of events per time interval, and *x!* means "x factorial". The factorial operation means to multiply a value by all decreasing integers down to 1, so *4! = 4 x 3 x 2 x 1 = 24*. To come up with a value for $\mu$, one must either specify a value *a priori*, or observe a real system long enough that you are satisfied with your estimate. 

```{r echo=FALSE}
vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,1 ), xlab="trials", ylab="density", main="Poisson distributions", axes=FALSE, ylim=c(0,0.4) )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)

vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,2 ), xlab="trials", ylab="density", main="Poisson distributions", axes=FALSE, ylim=c(0,0.4) )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)

vals = seq(from=0, to=15, by=1)
par(mar=c(4,4,1,1))
b=barplot(dpois(vals,3 ), xlab="trials", ylab="density", main="Poisson distributions", axes=FALSE, ylim=c(0,0.4), col="#0000ff11" )
axis(1, at=c( b[1], b[5], b[10], b[15]), labels=c(0, 5, 10, 15) )
axis(2, seq(0,0.5,0.1), las=1)
```

The Poisson approximation to the Binomial Distribution
--------------------------------------------------------------------------------

The Poisson distribution can be used to approximate the Binomial distribution, but this approximation is only accurate for rare events, e.g. those where the probability in any unit time window is less than 10%. Now that we can evaluate either of these distributions using packages such as R, the savings in computational complexity at the cost of loss of accuracy is less relevant than it once was.


Examples of applying the Poisson distribution
--------------------------------------------------------------------------------

**EXAMPLE ONE**:

A graduate student observes that most days, her principle investigator drinks two cups of espresso. What is the probability that the supervisor will drink three cups of expresso?

*Answer:* Here $\mu$ = 2, and we are asked to calculate P(3).

Since $\large{ P(X) = \frac{e^{-\mu}\mu^x }{x!} }$, $\large{ P(3) = \frac{e^{-2}\times2^3 }{3!} } = 0.180447$, or 18%.

> To raise *e* to a value in R, use the exp() function.

**EXAMPLE TWO**:

Mice of the strain RX47 usually produce five healthy pups in a litter. You have recently changed their chow to pellets produced by a different supplier, and the next litter from your RX47 mice has only three pups. Should you be worried? What are the chances that this might happen by chance?

*Answer:* Here $\mu$ = 5, and we are asked to calculate P(3).

$\large{ P(3) = \frac{e^{-5}\times5^3 }{3!} } = 0.2807$, or 28%. 

Not very strong evidence that the chow is associated with lower litter sizes.

**EXAMPLE THREE**

Robert the Post Doc typically stays at the lab after 8:00 p.m. five times as week. What are the chances that Robert will miss dinner today?

The average number of days per week Robert is at work past 8:00 p.m. is $\frac{5}{7} = 0.71$. The probability that Robert will have a late night is $\frac{e^{-0.71}\times0.71^1}{1!}$ = 0.349 = 35%.


In this case, we can also calculate the probability of a late night using the Binomial distribution:

$P_{late} = 0.71$, $P_{not late} = 0.29$, so 

$\large{ {n \choose x} p^x(1-p)^{(n-x)} }$



