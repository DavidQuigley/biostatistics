---
title: 'Module 5.3: Small samples and Studentâ€™s t distribution'
author: "David Quigley"
output:
  html_document:
    css: swiss.css
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

[Return to the table of contents](index.html)

********************************************************************************

Introduction
========================================

**This module explains:**

* Why the *t* distribution exists
* How the degrees of freedom quantify the amount of independent information in the sample
* How to calculate confidence intervals for small samples



Small samples and the t distribution
================================================================================

The fact that as the number of observations increase, the distribution values will often tend towards a normal frequency distribution allows statisticians to make important inferences about statistical properties. However, in practice, due to experimental costs or the availability of subject populations, **scientists often are constrained to use small sample sizes**. The *t* distribution is very useful in these cases. 


The rationale for the *t* distribution:

>For small samples, where the sample estimates are less representative of the population, *t* provides an alternative to the normal curve that is more conservative.

The *t* distribution is sometimes named Student's *t* distribution after the pseudonym of the statistician William Sealy Gosset, who developed it while working at the Guiness Brewery.

The *t* distribution describes the **frequency distribution of small numbers of samples chosen from a normal distribution**. Like the normal distribution, the function that defines its probability density is complex and understanding it is not required to make use of the *t* distribution.

Defining the t statistic
---------------------------

The t distribution looks a lot like the normal distribution, but it does not approach zero as quickly:

```{r echo=FALSE, fig.height=4, fig.width=5}
vals = seq(from=-7,to=7, by=0.01)
par(mar=c(4,4,1,1))
plot(dt( vals, df=1 ), type="l", yaxs="i", xaxs="i", lwd=3, axes=FALSE, 
     xlab="t statistic", ylab="density", main="t and standard normal distribution", ylim=c(0,.4) )
points( dnorm( vals ), type="l", lwd=3, col="gray" )
legend( 900,0.35, c("t DF=1", "normal"), col=c("black", "gray"), pch=19)
axis(2, seq(from=0, to=0.4, by=0.1), las=1)
axis(1, at=( length(vals) / 14 * 0:14) , labels=seq(from=-7, to=7, by=1), las=1)
```

**Figure 1: the t distribution with 1 degree of freedom**

Note that the tails of the *t* distribution in **Figure 1**, plotted in black, have higher probabilities than the corresponding points on a normal distribution with the same mean and SD = 1, plotted in grey. Since the probability function for this *t* distribution has a higher Y value for values of X more distant from the mean, the interpretation is that these values are more likely to occur. Therefore, **the *t* distribution is more conservative**.

The formula describing the *t* distribution is rather complicated. In the past to derive a specific value for the distribution, given a value for *t* and the number of degrees of freedom (defined below), one would have used a table of pre-computed values. Nowadays we can use a statistical package such as R to do this. 

Degrees of Freedom: how much information?
================================================================================

The purpose of using a *t* distribution in this kind of problem is to be more conservative, since our sample size is small. However, if we have more observatioons in our sample, we can be less conservative because having more independent sample observations improves our estimate of the population value.

The "degrees of freedom" is a way to quantify how much independent information we have in our estimate. A higher value for degrees of freedom means our samples contain more independent data. In the context of the *t* distribution, that means we can be less conservative.

As the number of degrees of freedom increases, the *t* distribution shape changes and becomes more and more like a normal distribution.

Samples from a *t* distribution made *N* observations have N-1 degrees of freedom. The rationale is as follows:

Recall that for *n* samples, the sample mean is defined:

$\bar{x} = \frac{x_1 + ... + x_n}{n}$ 

and the sample variance is defined:

$s^2 = \frac{ \sum_{i=1}^n(x_i-\bar{x})^2 }{n-1}$. 

To calculate the sample variance, we need to know the sample mean. If we have a small sample of five observations, how many indepdenent observations go into calculating the variance? Since, given the mean and four values, we can calculate what the fifth value must be, there are four independent values in five observations.

```{r echo=FALSE, fig.height=4, fig.width=5}
plot(dt( vals, df=1 ), type="l", yaxs="i", xaxs="i", lwd=3, axes=FALSE, 
     xlab="t statistic", ylab="density", main="t and standard normal distribution", ylim=c(0,.4) )
axis(2, seq(from=0, to=0.4, by=0.1), las=1)
axis(1, at=( length(vals) / 14 * 0:14) , labels=seq(from=-7, to=7, by=1), las=1)
points( dt( vals, df=3 ), type="l", lwd=3, col="cornflowerblue" )
points( dt( vals, df=6 ), type="l", lwd=3, col="gold" )
points( dt( vals, df=20 ), type="l", lwd=3, col="darkgreen" )
points( dnorm( vals ), type="l", lwd=3, col="gray" )
legend( 900,0.35, c("t DF=1","t DF=3","t DF=6","t DF=20", "normal"), col=c("black", "cornflowerblue", "gold", "darkgreen", "gray"), pch=19)
```

**Figure 2: *t* distributions with various DF**

In **Figure 2** I have plotted four different *t* distributions. All of these curves are derived from the same equation, but with different values for the Degrees of Freedom. As the DF goes up, the curves become more and more similar to the normal distribution plotted in grey.

Calculating Confidence Intervals using the *t* distribution
================================================================================

Calculating CI
----------------

The method of calculating a Confidence Interval (CI) using the *t* distribution has is similar to that used when calculating a CI using the normal distribution. However, the bounds of the *t* distribution will be different from those of the normal distribution.

1. calculate sample mean, standard error (SEM)
2. determine degrees of freedom (DF) (N-1)
3. use R to calculate the number of standard deviations from the mean that contain 95% of a t distribution with the DF

Example: confidence interval of the mean estimate:

```{r echo=FALSE}
library(knitr)
knitr::opts_chunk$set( comment = NA )
knitr::opts_chunk$set( prompt=TRUE ) 
```


```{r}
obs = c(2,5,7,8,3)
N = length(obs)
SEM = sd(obs) / sqrt(N)
degrees_of_freedom = N-1
CI_bound =  qt( (0.05/2), df=degrees_of_freedom) 
lower_bound = round( mean(obs) - ( abs(CI_bound) * SEM ), 1) 
upper_bound = round( mean(obs) + ( abs(CI_bound) * SEM ), 1)
print( paste( "mean", mean(obs), "95% CI", lower_bound, "to", upper_bound, 
              "on", degrees_of_freedom, "DF") )
```

So given these five observations with mean `r mean(obs)`, the 95% CI ranges from `r lower_bound` to `r upper_bound`.

Comparison to a CI from the normal distribution
----------------

If we perform the same calculations using the bounds set by a normal distribution, the confidence interval will be smaller (less conservative). This is not the best choice here, as the small sample size indicates we should use the t distribution instead.

```{r}
obs = c(2,5,7,8,3)
N= length(obs)
SEM = sd(obs) / sqrt(N)
lower_bound_nor = round( mean(obs) - ( 1.96 * SEM ), 1) 
upper_bound_nor = round( mean(obs) + ( 1.96 * SEM ), 1)
print( paste( "mean", mean(obs), "95% CI", lower_bound_nor, "to", upper_bound_nor) )
```



Summary
=========

* *t* distribution has a similar shape to a normal curve
    + more conservative at the tails
	+ more appropriate for small samples from a normal distribution
	
* Degrees of Freedom (DF) quantifies independent information in our estimate.
    + *t* becomes more like normal as DF increases


R code examples
=======================

> The t distribution value for a given number of degrees of freedom

```{r}
t_value = 3
degrees_of_freedom=5
dt(t_value, df=degrees_of_freedom)

```
